{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on CUDA:  NVIDIA GeForce RTX 4070\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda:0\")\n",
    "  print(\"Running on CUDA: \", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "else:\n",
    "  device = torch.device(\"cpu\")\n",
    "  print(\"Running on CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in training data\n",
    "df = pd.read_csv('./data/movementSensorData.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>activity</th>\n",
       "      <th>time_s</th>\n",
       "      <th>lw_x</th>\n",
       "      <th>lw_y</th>\n",
       "      <th>lw_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63804</td>\n",
       "      <td>2</td>\n",
       "      <td>638.05</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>-0.941</td>\n",
       "      <td>-0.316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63805</td>\n",
       "      <td>2</td>\n",
       "      <td>638.06</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>-0.879</td>\n",
       "      <td>-0.320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63806</td>\n",
       "      <td>2</td>\n",
       "      <td>638.07</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>-0.852</td>\n",
       "      <td>-0.305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63807</td>\n",
       "      <td>2</td>\n",
       "      <td>638.08</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>-0.879</td>\n",
       "      <td>-0.277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63808</td>\n",
       "      <td>2</td>\n",
       "      <td>638.09</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.941</td>\n",
       "      <td>-0.242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  activity  time_s   lw_x   lw_y   lw_z\n",
       "0  63804         2  638.05 -0.188 -0.941 -0.316\n",
       "1  63805         2  638.06 -0.121 -0.879 -0.320\n",
       "2  63806         2  638.07 -0.070 -0.852 -0.305\n",
       "3  63807         2  638.08 -0.023 -0.879 -0.277\n",
       "4  63808         2  638.09  0.008 -0.941 -0.242"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(507827, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>activity</th>\n",
       "      <th>time_s</th>\n",
       "      <th>lw_x</th>\n",
       "      <th>lw_y</th>\n",
       "      <th>lw_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>507827.000000</td>\n",
       "      <td>507827.000000</td>\n",
       "      <td>507827.000000</td>\n",
       "      <td>507827.000000</td>\n",
       "      <td>507827.000000</td>\n",
       "      <td>507827.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>167785.101830</td>\n",
       "      <td>4.191809</td>\n",
       "      <td>1677.861018</td>\n",
       "      <td>-0.211302</td>\n",
       "      <td>-0.021941</td>\n",
       "      <td>-0.477602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>63888.316941</td>\n",
       "      <td>8.785676</td>\n",
       "      <td>638.883169</td>\n",
       "      <td>0.524070</td>\n",
       "      <td>0.727952</td>\n",
       "      <td>0.443465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>63804.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>638.050000</td>\n",
       "      <td>-5.289000</td>\n",
       "      <td>-5.305000</td>\n",
       "      <td>-6.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>89195.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>891.960000</td>\n",
       "      <td>-0.734000</td>\n",
       "      <td>-0.219000</td>\n",
       "      <td>-0.828000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>188844.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1888.450000</td>\n",
       "      <td>-0.098000</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>-0.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>220583.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2205.840000</td>\n",
       "      <td>0.176000</td>\n",
       "      <td>0.426000</td>\n",
       "      <td>-0.148000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>252322.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>2523.230000</td>\n",
       "      <td>5.516000</td>\n",
       "      <td>4.418000</td>\n",
       "      <td>4.551000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id       activity         time_s           lw_x  \\\n",
       "count  507827.000000  507827.000000  507827.000000  507827.000000   \n",
       "mean   167785.101830       4.191809    1677.861018      -0.211302   \n",
       "std     63888.316941       8.785676     638.883169       0.524070   \n",
       "min     63804.000000       1.000000     638.050000      -5.289000   \n",
       "25%     89195.000000       2.000000     891.960000      -0.734000   \n",
       "50%    188844.000000       4.000000    1888.450000      -0.098000   \n",
       "75%    220583.000000       4.000000    2205.840000       0.176000   \n",
       "max    252322.000000      77.000000    2523.230000       5.516000   \n",
       "\n",
       "                lw_y           lw_z  \n",
       "count  507827.000000  507827.000000  \n",
       "mean       -0.021941      -0.477602  \n",
       "std         0.727952       0.443465  \n",
       "min        -5.305000      -6.875000  \n",
       "25%        -0.219000      -0.828000  \n",
       "50%         0.184000      -0.570000  \n",
       "75%         0.426000      -0.148000  \n",
       "max         4.418000       4.551000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "activity    0\n",
       "time_s      0\n",
       "lw_x        0\n",
       "lw_y        0\n",
       "lw_z        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2, 77,  1,  3,  4], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['activity'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have activites 1, 2, 3, 4, and 77. From the source (https://physionet.org/content/accelerometry-walk-climb-drive/1.0.0/#files) we know that these are:\n",
    "- 1 Walking\n",
    "- 2 Descending Stairs\n",
    "- 3 Ascending Stairs\n",
    "- 4 Driving\n",
    "- 77 Clapping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "scaler.fit(df)\n",
    "scaler_train = scaler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        time_s   lw_x   lw_y   lw_z\n",
      "0       638.05 -0.188 -0.941 -0.316\n",
      "1       638.06 -0.121 -0.879 -0.320\n",
      "2       638.07 -0.070 -0.852 -0.305\n",
      "3       638.08 -0.023 -0.879 -0.277\n",
      "4       638.09  0.008 -0.941 -0.242\n",
      "...        ...    ...    ...    ...\n",
      "507822  963.87 -0.012  0.984 -0.363\n",
      "507823  963.88  0.016  0.938 -0.379\n",
      "507824  963.89  0.039  0.910 -0.391\n",
      "507825  963.90  0.066  0.898 -0.395\n",
      "507826  963.91  0.105  0.895 -0.398\n",
      "\n",
      "[507827 rows x 4 columns]\n",
      "0         2\n",
      "1         2\n",
      "2         2\n",
      "3         2\n",
      "4         2\n",
      "         ..\n",
      "507822    1\n",
      "507823    1\n",
      "507824    1\n",
      "507825    1\n",
      "507826    1\n",
      "Name: activity, Length: 507827, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:, 2:6] #time and data minus activity\n",
    "y = df.iloc[:, 1] #just activity\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ts_cv = TimeSeriesSplit(\n",
    "#    n_splits=5,\n",
    "#    gap=48,\n",
    "#    max_train_size=10000,\n",
    "#    test_size=1000,\n",
    "#)\n",
    "#\n",
    "#all_splits = list(ts_cv.split(X, y))\n",
    "#train_0, test_0 = all_splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n",
    "X_test, X_validation, y_test, y_validation = train_test_split(X_test, y_test, test_size=0.5, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-Learn RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random_forest = RandomForestClassifier(max_depth=16, random_state=1452, n_estimators=1000)\n",
    "#random_forest.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = random_forest.predict(X_validation)\n",
    "#print('accuracy', metrics.accuracy_score(y_validation, y_pred))\n",
    "#print('f1', metrics.f1_score(y_validation, y_pred, average='weighted'))\n",
    "##accuracy 0.9750113226867259\n",
    "##f1 0.9736860087875407"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('models/random_forest.pickle', 'wb') as rf_file:\n",
    "#    pickle.dump(random_forest, rf_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch NN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\daniel\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\utils\\data\\dataset.py:348: UserWarning: Length of split at index 1 is 0. This might result in an empty dataset.\n",
      "  warnings.warn(f\"Length of split at index {i} is 0. \"\n"
     ]
    }
   ],
   "source": [
    "#Split train into training/validation\n",
    "X_tensor = X.values.astype(np.float32)\n",
    "y_tensor = y.values.astype(np.float32)\n",
    "data_tensor_tuple = (X_tensor, y_tensor)\n",
    "training, validation = torch.utils.data.random_split(data_tensor_tuple, [0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseMLP(nn.Module):\n",
    "  def __init__(self, input_size, hidden_width, hidden_depth, activation_func,\n",
    "               dropout=0, num_classes=5):\n",
    "    super().__init__()\n",
    "\n",
    "    operations = [\n",
    "        nn.Linear(input_size, hidden_width), #input layer -> hidden layer\n",
    "        #nn.BatchNorm1d(hidden_width),\n",
    "        #nn.Dropout(dropout),\n",
    "        activation_func\n",
    "    ]\n",
    "\n",
    "    if (hidden_depth > 2): #shrink_width used to scale down the width (number of nodes) per layer\n",
    "      shrink_width = int(hidden_width / (hidden_depth - 1))\n",
    "\n",
    "    for i in range(2, hidden_depth):\n",
    "      next_width = int(hidden_width - shrink_width)\n",
    "      operations.extend([\n",
    "          nn.Linear(hidden_width, next_width), #hidden layer i -> hidden layer i + 1\n",
    "          #nn.BatchNorm1d(next_width),\n",
    "          #nn.Dropout(dropout),\n",
    "          activation_func\n",
    "      ])\n",
    "      hidden_width = next_width\n",
    "\n",
    "    operations.append(nn.Linear(hidden_width, num_classes)) #hidden layer -> output layer\n",
    "\n",
    "    self.sequence = nn.Sequential(*operations)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    out = self.sequence(x)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 12\u001b[0m\n\u001b[0;32m      6\u001b[0m baseline_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m      8\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(dataset\u001b[38;5;241m=\u001b[39mtraining, \n\u001b[0;32m      9\u001b[0m                                            batch_size\u001b[38;5;241m=\u001b[39mbaseline_batch_size, \n\u001b[0;32m     10\u001b[0m                                            shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 12\u001b[0m valid_loader \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaseline_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m baseline_model \u001b[38;5;241m=\u001b[39m BaseMLP(\u001b[38;5;241m4\u001b[39m, baseline_hidden_width, \n\u001b[0;32m     18\u001b[0m                          baseline_hidden_depth, baseline_activation_func, \n\u001b[0;32m     19\u001b[0m                          dropout\u001b[38;5;241m=\u001b[39mbaseline_dropout)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     21\u001b[0m baseline_optimiser \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(baseline_model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mbaseline_learning_rate)\n",
      "File \u001b[1;32mc:\\Users\\daniel\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:351\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[1;32m--> 351\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    353\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\daniel\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\utils\\data\\sampler.py:107\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[1;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    104\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement))\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    108\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue, but got num_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples))\n",
      "\u001b[1;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "baseline_learning_rate = 0.001\n",
    "baseline_dropout = 0.0\n",
    "baseline_hidden_width = 40\n",
    "baseline_hidden_depth = 2\n",
    "baseline_activation_func = nn.ReLU()\n",
    "baseline_batch_size = 100\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=training, \n",
    "                                           batch_size=baseline_batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=validation, \n",
    "                                          batch_size=baseline_batch_size, \n",
    "                                          shuffle=True)\n",
    "\n",
    "\n",
    "baseline_model = BaseMLP(4, baseline_hidden_width, \n",
    "                         baseline_hidden_depth, baseline_activation_func, \n",
    "                         dropout=baseline_dropout).to(device)\n",
    "\n",
    "baseline_optimiser = torch.optim.Adam(baseline_model.parameters(), lr=baseline_learning_rate)\n",
    "\n",
    "baseline_lr_scheduler = torch.optim.lr_scheduler.StepLR(baseline_optimiser, step_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb00558b1a04c3885513c910f72fc14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<enumerate object at 0x00000273C7C92D80>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m running_total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28menumerate\u001b[39m(data_tensor_tuple))\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (X_train_i, y_train_i) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_tensor_tuple):\n\u001b[0;32m     14\u001b[0m   \u001b[38;5;66;03m# move tensors to device (CPU or GPU)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m   X_train_i \u001b[38;5;241m=\u001b[39m X_train_i\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     16\u001b[0m   y_train_i \u001b[38;5;241m=\u001b[39m y_train_i\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "#def trainModel(num_epochs, model, data, criterion, optimizer, scheduler):\n",
    "baseline_model.train() #model in train mode\n",
    "epochs = notebook.tqdm(range(num_epochs))\n",
    "\n",
    "loss_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "for epoch in epochs:\n",
    "  total_loss = 0\n",
    "  correct = 0\n",
    "  running_total = 0\n",
    "  for i, (X_train_i, y_train_i) in enumerate(train_loader):\n",
    "    # move tensors to device (CPU or GPU)\n",
    "    X_train_i = X_train_i.to(device)\n",
    "    y_train_i = y_train_i.to(device)\n",
    "\n",
    "    #forward pass\n",
    "    predictions = baseline_model(X_train_i)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    print('predictions', predictions)\n",
    "    print('y_train_i', y_train_i)\n",
    "    loss(predictions, y_train_i)\n",
    "    \n",
    "    #backward pass, optimise\n",
    "    loss.backward() #backprop the loss\n",
    "    total_loss += loss.item()\n",
    "    \n",
    "    baseline_optimiser.step()\n",
    "    baseline_optimiser.zero_grad()\n",
    "\n",
    "    _, predicted = torch.max(predictions.data, 1)\n",
    "    correct += (predicted == y_train_i).sum().item()\n",
    "    running_total += y_train_i.size(0)\n",
    "\n",
    "    if (i + 1) % 10 == 0: #update progress bar every 10 batches\n",
    "      epochs.set_description(f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i+1}/{len(training)}], Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    loss_list.append(total_loss)\n",
    "    accuracy_list.append(100 * correct / running_total)\n",
    "    baseline_lr_scheduler.step() #np.mean(loss_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline_predictions, baseline_valid_accuracy = testModel(baseline_model, X_validation, y_validation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f24698e55fd56b44836dbda41ecc9d71a75eb009750c386f57c76f2a6e67678"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
