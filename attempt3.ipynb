{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on CUDA:  NVIDIA GeForce RTX 4070\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda:0\")\n",
    "  print(\"Running on CUDA: \", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "else:\n",
    "  device = torch.device(\"cpu\")\n",
    "  print(\"Running on CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in training data\n",
    "df = pd.read_csv('./data/movementSensorData.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>activity</th>\n",
       "      <th>time_s</th>\n",
       "      <th>lw_x</th>\n",
       "      <th>lw_y</th>\n",
       "      <th>lw_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63804</td>\n",
       "      <td>2</td>\n",
       "      <td>638.05</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>-0.941</td>\n",
       "      <td>-0.316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63805</td>\n",
       "      <td>2</td>\n",
       "      <td>638.06</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>-0.879</td>\n",
       "      <td>-0.320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63806</td>\n",
       "      <td>2</td>\n",
       "      <td>638.07</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>-0.852</td>\n",
       "      <td>-0.305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63807</td>\n",
       "      <td>2</td>\n",
       "      <td>638.08</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>-0.879</td>\n",
       "      <td>-0.277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63808</td>\n",
       "      <td>2</td>\n",
       "      <td>638.09</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.941</td>\n",
       "      <td>-0.242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  activity  time_s   lw_x   lw_y   lw_z\n",
       "0  63804         2  638.05 -0.188 -0.941 -0.316\n",
       "1  63805         2  638.06 -0.121 -0.879 -0.320\n",
       "2  63806         2  638.07 -0.070 -0.852 -0.305\n",
       "3  63807         2  638.08 -0.023 -0.879 -0.277\n",
       "4  63808         2  638.09  0.008 -0.941 -0.242"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(507827, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>activity</th>\n",
       "      <th>time_s</th>\n",
       "      <th>lw_x</th>\n",
       "      <th>lw_y</th>\n",
       "      <th>lw_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>507827.000000</td>\n",
       "      <td>507827.000000</td>\n",
       "      <td>507827.000000</td>\n",
       "      <td>507827.000000</td>\n",
       "      <td>507827.000000</td>\n",
       "      <td>507827.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>167785.101830</td>\n",
       "      <td>4.191809</td>\n",
       "      <td>1677.861018</td>\n",
       "      <td>-0.211302</td>\n",
       "      <td>-0.021941</td>\n",
       "      <td>-0.477602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>63888.316941</td>\n",
       "      <td>8.785676</td>\n",
       "      <td>638.883169</td>\n",
       "      <td>0.524070</td>\n",
       "      <td>0.727952</td>\n",
       "      <td>0.443465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>63804.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>638.050000</td>\n",
       "      <td>-5.289000</td>\n",
       "      <td>-5.305000</td>\n",
       "      <td>-6.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>89195.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>891.960000</td>\n",
       "      <td>-0.734000</td>\n",
       "      <td>-0.219000</td>\n",
       "      <td>-0.828000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>188844.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1888.450000</td>\n",
       "      <td>-0.098000</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>-0.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>220583.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2205.840000</td>\n",
       "      <td>0.176000</td>\n",
       "      <td>0.426000</td>\n",
       "      <td>-0.148000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>252322.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>2523.230000</td>\n",
       "      <td>5.516000</td>\n",
       "      <td>4.418000</td>\n",
       "      <td>4.551000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id       activity         time_s           lw_x  \\\n",
       "count  507827.000000  507827.000000  507827.000000  507827.000000   \n",
       "mean   167785.101830       4.191809    1677.861018      -0.211302   \n",
       "std     63888.316941       8.785676     638.883169       0.524070   \n",
       "min     63804.000000       1.000000     638.050000      -5.289000   \n",
       "25%     89195.000000       2.000000     891.960000      -0.734000   \n",
       "50%    188844.000000       4.000000    1888.450000      -0.098000   \n",
       "75%    220583.000000       4.000000    2205.840000       0.176000   \n",
       "max    252322.000000      77.000000    2523.230000       5.516000   \n",
       "\n",
       "                lw_y           lw_z  \n",
       "count  507827.000000  507827.000000  \n",
       "mean       -0.021941      -0.477602  \n",
       "std         0.727952       0.443465  \n",
       "min        -5.305000      -6.875000  \n",
       "25%        -0.219000      -0.828000  \n",
       "50%         0.184000      -0.570000  \n",
       "75%         0.426000      -0.148000  \n",
       "max         4.418000       4.551000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "activity    0\n",
       "time_s      0\n",
       "lw_x        0\n",
       "lw_y        0\n",
       "lw_z        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2, 77,  1,  3,  4], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['activity'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have activites 1, 2, 3, 4, and 77. From the source (https://physionet.org/content/accelerometry-walk-climb-drive/1.0.0/#files) we know that these are:\n",
    "- 1 Walking\n",
    "- 2 Descending Stairs\n",
    "- 3 Ascending Stairs\n",
    "- 4 Driving\n",
    "- 77 Clapping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "scaler.fit(df)\n",
    "scaler_train = scaler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        time_s   lw_x   lw_y   lw_z\n",
      "0       638.05 -0.188 -0.941 -0.316\n",
      "1       638.06 -0.121 -0.879 -0.320\n",
      "2       638.07 -0.070 -0.852 -0.305\n",
      "3       638.08 -0.023 -0.879 -0.277\n",
      "4       638.09  0.008 -0.941 -0.242\n",
      "...        ...    ...    ...    ...\n",
      "507822  963.87 -0.012  0.984 -0.363\n",
      "507823  963.88  0.016  0.938 -0.379\n",
      "507824  963.89  0.039  0.910 -0.391\n",
      "507825  963.90  0.066  0.898 -0.395\n",
      "507826  963.91  0.105  0.895 -0.398\n",
      "\n",
      "[507827 rows x 4 columns]\n",
      "0         2\n",
      "1         2\n",
      "2         2\n",
      "3         2\n",
      "4         2\n",
      "         ..\n",
      "507822    1\n",
      "507823    1\n",
      "507824    1\n",
      "507825    1\n",
      "507826    1\n",
      "Name: activity, Length: 507827, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:, 2:6] #time and data minus activity\n",
    "y = df.iloc[:, 1] #just activity\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ts_cv = TimeSeriesSplit(\n",
    "#    n_splits=5,\n",
    "#    gap=48,\n",
    "#    max_train_size=10000,\n",
    "#    test_size=1000,\n",
    "#)\n",
    "#\n",
    "#all_splits = list(ts_cv.split(X, y))\n",
    "#train_0, test_0 = all_splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n",
    "X_test, X_validation, y_test, y_validation = train_test_split(X_test, y_test, test_size=0.5, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-Learn RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random_forest = RandomForestClassifier(max_depth=16, random_state=1452, n_estimators=1000)\n",
    "#random_forest.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = random_forest.predict(X_validation)\n",
    "#print('accuracy', metrics.accuracy_score(y_validation, y_pred))\n",
    "#print('f1', metrics.f1_score(y_validation, y_pred, average='weighted'))\n",
    "##accuracy 0.9750113226867259\n",
    "##f1 0.9736860087875407"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('models/random_forest.pickle', 'wb') as rf_file:\n",
    "#    pickle.dump(random_forest, rf_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch NN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 2 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m X_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(X\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32))\n\u001b[0;32m      3\u001b[0m y_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(y\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32))\n\u001b[1;32m----> 4\u001b[0m training, validation \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mrandom_split(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tensor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, [\u001b[38;5;241m0.7\u001b[39m, \u001b[38;5;241m0.3\u001b[39m])\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 2 and 1"
     ]
    }
   ],
   "source": [
    "#Split train into training/validation\n",
    "X_tensor = torch.from_numpy(X.values.astype(np.float32))\n",
    "y_tensor = torch.from_numpy(y.values.astype(np.float32))\n",
    "training, validation = torch.utils.data.random_split(torch.cat(tensors=(X_tensor, y_tensor)), [0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseMLP(nn.Module):\n",
    "  def __init__(self, input_size, hidden_width, hidden_depth, activation_func,\n",
    "               dropout=0, num_classes=5):\n",
    "    super().__init__()\n",
    "\n",
    "    operations = [\n",
    "        nn.Linear(input_size, hidden_width), #input layer -> hidden layer\n",
    "        #nn.BatchNorm1d(hidden_width),\n",
    "        #nn.Dropout(dropout),\n",
    "        activation_func\n",
    "    ]\n",
    "\n",
    "    if (hidden_depth > 2): #shrink_width used to scale down the width (number of nodes) per layer\n",
    "      shrink_width = int(hidden_width / (hidden_depth - 1))\n",
    "\n",
    "    for i in range(2, hidden_depth):\n",
    "      next_width = int(hidden_width - shrink_width)\n",
    "      operations.extend([\n",
    "          nn.Linear(hidden_width, next_width), #hidden layer i -> hidden layer i + 1\n",
    "          #nn.BatchNorm1d(next_width),\n",
    "          #nn.Dropout(dropout),\n",
    "          activation_func\n",
    "      ])\n",
    "      hidden_width = next_width\n",
    "\n",
    "    operations.append(nn.Linear(hidden_width, num_classes)) #hidden layer -> output layer\n",
    "\n",
    "    self.sequence = nn.Sequential(*operations)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    out = self.sequence(x)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_learning_rate = 0.001\n",
    "baseline_dropout = 0.0\n",
    "baseline_hidden_width = 40\n",
    "baseline_hidden_depth = 2\n",
    "baseline_activation_func = nn.ReLU()\n",
    "\n",
    "baseline_model = BaseMLP(4, baseline_hidden_width, \n",
    "                         baseline_hidden_depth, baseline_activation_func, \n",
    "                         dropout=baseline_dropout).to(device)\n",
    "\n",
    "baseline_optimiser = torch.optim.Adam(baseline_model.parameters(), lr=baseline_learning_rate)\n",
    "\n",
    "baseline_lr_scheduler = torch.optim.lr_scheduler.StepLR(baseline_optimiser, step_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48774b3ea9bd4bb2bd7ab6559ff8dff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 9.1655e+02, -3.0500e-01, -1.1800e+00, -1.4100e-01], device='cuda:0')\n",
      "predictions tensor([ -27.1389,   33.7549, -172.7104,  -85.9163, -163.1038],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "y_train_i tensor(927.2100, device='cuda:0')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\"nll_loss_forward_reduce_cuda_kernel_1d_index\" not implemented for 'Float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictions\u001b[39m\u001b[38;5;124m'\u001b[39m, predictions)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_train_i\u001b[39m\u001b[38;5;124m'\u001b[39m, y_train_i)\n\u001b[1;32m---> 23\u001b[0m \u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_i\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m#backward pass, optimise\u001b[39;00m\n\u001b[0;32m     26\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward() \u001b[38;5;66;03m#backprop the loss\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\daniel\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\daniel\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1176\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\daniel\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\functional.py:3029\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3027\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3028\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3029\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: \"nll_loss_forward_reduce_cuda_kernel_1d_index\" not implemented for 'Float'"
     ]
    }
   ],
   "source": [
    "#def trainModel(num_epochs, model, data, criterion, optimizer, scheduler):\n",
    "baseline_model.train() #model in train mode\n",
    "epochs = notebook.tqdm(range(num_epochs))\n",
    "\n",
    "loss_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "for epoch in epochs:\n",
    "  total_loss = 0\n",
    "  correct = 0\n",
    "  running_total = 0\n",
    "  for i in range(len(training)):\n",
    "    # move tensors to device (CPU or GPU)\n",
    "    X_train_i = training[:-1][i].to(device)\n",
    "    y_train_i = training[-1][i].to(device)\n",
    "\n",
    "    #forward pass\n",
    "    predictions = baseline_model(X_train_i)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    print('predictions', predictions)\n",
    "    print('y_train_i', y_train_i)\n",
    "    loss(predictions, y_train_i)\n",
    "    \n",
    "    #backward pass, optimise\n",
    "    loss.backward() #backprop the loss\n",
    "    total_loss += loss.item()\n",
    "    \n",
    "    baseline_optimiser.step()\n",
    "    baseline_optimiser.zero_grad()\n",
    "\n",
    "    _, predicted = torch.max(predictions.data, 1)\n",
    "    correct += (predicted == y_train_i).sum().item()\n",
    "    running_total += y_train_i.size(0)\n",
    "\n",
    "    if (i + 1) % 10 == 0: #update progress bar every 10 batches\n",
    "      epochs.set_description(f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i+1}/{len(training)}], Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    loss_list.append(total_loss)\n",
    "    accuracy_list.append(100 * correct / running_total)\n",
    "    baseline_lr_scheduler.step() #np.mean(loss_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline_predictions, baseline_valid_accuracy = testModel(baseline_model, X_validation, y_validation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f24698e55fd56b44836dbda41ecc9d71a75eb009750c386f57c76f2a6e67678"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
